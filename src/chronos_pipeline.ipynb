{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d1e56b-193d-4c38-a7fe-cf181d868c2d",
   "metadata": {},
   "source": [
    "<sup> Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved. </sup>\n",
    "<sup> SPDX-License-Identifier: MIT-0 </sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8c27a3-5eb4-4ea3-8489-16e002c6c4c7",
   "metadata": {},
   "source": [
    "# Chronos Pipeline - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327fc9ac-67dd-4904-a3b6-c48865b36078",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to demonstrate how to train a Chronos model using Amazon SageMaker.\n",
    "\n",
    "**Jupyter Kernel**:\n",
    "\n",
    "- Please ensure you are using the **Python 3 (Pytorch 2.1.0 Python 3.10 CPU Optimized)** kernel\n",
    "\n",
    "**Run All**:\n",
    "\n",
    "- If you are in a SageMaker Notebook instance, you can go to *Cell tab -> Run All*\n",
    "- If you are in SageMaker Studio, you can go to *Run tab -> Run All Cells*\n",
    "\n",
    "**Overview**:\n",
    "- [Pipeline Configuration](#pipeline_configuration)\n",
    "- [Data Generation and Processing](#data_processing)\n",
    "- [Model Training and Hyperparameter Tuning](#training)\n",
    "- [Model Registration](#model_registration)\n",
    "- [Pipeline Execution](#pipeline_execution)\n",
    "\n",
    "**Authors**:\n",
    "- Alston Chan\n",
    "- Maria Masood\n",
    "- Nick Biso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d10647-99bd-42c7-957a-5e36027d8dcd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.processing import ProcessingOutput\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.pytorch import PyTorch, PyTorchProcessor\n",
    "from sagemaker.tuner import ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.pipeline_experiment_config import PipelineExperimentConfig\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "from sagemaker.workflow.steps import ProcessingStep, CacheConfig, TuningStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8524d30b-0d3e-4970-afa8-f6297e08d6fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.Session().region_name\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "s3_client = boto3.resource('s3')\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "s3_resource = boto3.resource('s3', region_name=region)\n",
    "s3_bucket = s3_resource.Bucket(bucket_name)\n",
    "\n",
    "print(f\"account_id: {account_id}\")\n",
    "print(f\"region: {region}\")\n",
    "print(f\"bucket_name: {bucket_name}\")\n",
    "print(f\"role: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b864e1-fc9b-46fd-9446-38208d326db3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='pipeline_configuration'></a>\n",
    "### Pipeline Configuration\n",
    "\n",
    "Before we dive into creating our SageMaker pipeline for training the Chronos model, we need to set up some key configuration variables. These variables will define the naming conventions for our project components and establish the necessary S3 paths for our pipeline artifacts.\n",
    "\n",
    "We will then define the parameters for our pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8bff79",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_name = \"chronos\"\n",
    "pipeline_name = project_name + \"-Pipeline\"\n",
    "experiment_name = pipeline_name + \"-Experiment\"\n",
    "model_package_group_name = project_name + \"-ModelGroup\"\n",
    "\n",
    "# Store variable for chronos_pipeline_endpoint_inference.ipynb\n",
    "%store model_package_group_name\n",
    "\n",
    "# Return an S3 path based on the id of this pipeline execution, which is a property only\n",
    "# resolved at runtime but can be accessed at compile time as an execution variable\n",
    "def dynamic_S3_path(path):\n",
    "    return Join(\n",
    "        on=\"/\",\n",
    "            values=[\n",
    "                \"s3:/\",\n",
    "                bucket_name,\n",
    "                pipeline_name,\n",
    "                \"executions\",\n",
    "                ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                path,\n",
    "            ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35edec-945e-4252-a4ea-9e3d67c2d3de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.p3.2xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e06472",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_session = PipelineSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095d5bc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache_config = CacheConfig(\n",
    "    enable_caching=True,\n",
    "    expire_after=\"7d\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c57c7e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_parameters = {}\n",
    "\n",
    "pipeline_parameters['train_data_size'] = ParameterInteger(\n",
    "    name=\"TrainDataSize\",\n",
    "    default_value=100,\n",
    ")\n",
    "\n",
    "pipeline_parameters['val_data_size'] = ParameterInteger(\n",
    "    name=\"ValidationDataSize\",\n",
    "    default_value=100,\n",
    ")\n",
    "\n",
    "pipeline_parameters['test_data_size'] = ParameterInteger(\n",
    "    name=\"TestDataSize\",\n",
    "    default_value=100,\n",
    ")\n",
    "\n",
    "pipeline_parameters['model_id'] = ParameterString(\n",
    "    name=\"ModelId\",\n",
    "    default_value=\"amazon/chronos-t5-small\"\n",
    ")\n",
    "\n",
    "pipeline_parameters['context_length'] = ParameterString(\n",
    "    name=\"ContextLength\", \n",
    "    default_value=\"100\"\n",
    ")\n",
    "\n",
    "pipeline_parameters['num_samples'] = ParameterString(\n",
    "    name=\"NumSamples\", \n",
    "    default_value=\"20\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846e216",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_parameters['training_instance_type'] = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35403feb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_parameters['max_jobs'] = ParameterInteger(\n",
    "    name=\"MaxJobs\", \n",
    "    default_value=2\n",
    ")\n",
    "\n",
    "pipeline_parameters['max_parallel_jobs'] = ParameterInteger(\n",
    "    name=\"MaxParallelJobs\", \n",
    "    default_value=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b68e8d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_parameter_list = list(pipeline_parameters.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de9bd9b-0483-4374-a121-52ccb27982a0",
   "metadata": {},
   "source": [
    "<a id='data_processing'></a>\n",
    "### Data Generation and Processing\n",
    "\n",
    "A crucial step in our Chronos model training pipeline is generating and processing the data. In this section, we'll set up a processing step that generates synthetic data for training, validation, and testing our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a42e5b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image_uri = image_uris.retrieve(\n",
    "    framework='pytorch',\n",
    "    region=region,\n",
    "    version='2.0',\n",
    "    py_version='py310',\n",
    "    image_scope='training', \n",
    "    instance_type=instance_type\n",
    ")\n",
    "\n",
    "inference_image_uri = image_uris.retrieve(\n",
    "    framework='pytorch',\n",
    "    region=region,\n",
    "    version='2.0',\n",
    "    py_version='py310',\n",
    "    image_scope='inference', \n",
    "    instance_type=instance_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2573359f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_job_name = f\"{pipeline_name}/data-generation-step\"\n",
    "\n",
    "script_processor = PyTorchProcessor( \n",
    "    command=['python3'],\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    base_job_name=base_job_name,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    framework_version='1.13',\n",
    "    py_version='py39'\n",
    ")\n",
    "\n",
    "processor_run_args = script_processor.run(\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/train\",\n",
    "            destination=dynamic_S3_path(\"train\")\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            source=\"/opt/ml/processing/validation\",\n",
    "            destination=dynamic_S3_path(\"validation\")\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/test\",\n",
    "            destination=dynamic_S3_path(\"test\")\n",
    "        ),\n",
    "    ],\n",
    "    code=\"processing/generate_data.py\",\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"GenerateData\",\n",
    "    step_args=processor_run_args,\n",
    "    job_arguments=[\n",
    "        \"--train_size\",\n",
    "        str(pipeline_parameters['train_data_size'].default_value),\n",
    "        \"--validation_size\",\n",
    "        str(pipeline_parameters['val_data_size'].default_value),\n",
    "        \"--test_size\",\n",
    "        str(pipeline_parameters['test_data_size'].default_value),\n",
    "    ],\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb7b5c0-13a5-4ad6-a442-da6dc6923408",
   "metadata": {},
   "source": [
    "<a id='training'></a>\n",
    "### Model Training and Hyperparameter Tuning\n",
    "\n",
    "After generating our data, the next crucial step in our pipeline is to train the Chronos model and optimize its hyperparameters. In this section, we will set up a hyperparameter tuning job that will search for the best model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07782cd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_component(model_name):\n",
    "    estimator = PyTorch(\n",
    "        role=role,\n",
    "        instance_type=pipeline_parameters['training_instance_type'],\n",
    "        output_path=f\"s3://{bucket_name}/{pipeline_name}/models/\",\n",
    "        instance_count=1,\n",
    "        source_dir='model',\n",
    "        image_uri=train_image_uri,\n",
    "        entry_point=model_name + \".py\",\n",
    "        base_job_name = f\"{pipeline_name}/training/job\",\n",
    "    )\n",
    "\n",
    "    hyper_ranges = {\n",
    "        'learning-rate': ContinuousParameter(1e-5, 1e-4),\n",
    "    }\n",
    "\n",
    "    objective_name = \"logloss\"\n",
    "    metric_definitions = [{\"Name\": objective_name, \"Regex\": \"'loss': ([0-9\\\\.]+),\"}]\n",
    "\n",
    "    tuner_log = HyperparameterTuner(\n",
    "        estimator,\n",
    "        objective_name,\n",
    "        hyper_ranges,\n",
    "        metric_definitions,\n",
    "        max_jobs=pipeline_parameters['max_jobs'], \n",
    "        max_parallel_jobs=pipeline_parameters['max_parallel_jobs'],\n",
    "        objective_type=\"Minimize\",\n",
    "        base_tuning_job_name=f\"{pipeline_name}/HPTuning/{model_name}\",\n",
    "        random_seed=10\n",
    "    )\n",
    "\n",
    "    step_tuning = TuningStep(\n",
    "        name=f\"{model_name}-HpTuning\",\n",
    "        display_name=f\"{model_name}-HpTuning\",\n",
    "        tuner=tuner_log,\n",
    "        inputs={\n",
    "            'train': TrainingInput(\n",
    "                s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "           \"validation\": TrainingInput(\n",
    "                s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "        },\n",
    "        job_arguments=[\n",
    "            \"--model_id\",\n",
    "            str(pipeline_parameters['model_id'].default_value),\n",
    "            \"--context_length\",\n",
    "            str(pipeline_parameters['context_length'].default_value),\n",
    "            \"--num_samples\",\n",
    "            str(pipeline_parameters['num_samples'].default_value),\n",
    "        ],\n",
    "        cache_config=cache_config\n",
    "    )\n",
    "    \n",
    "    return step_tuning\n",
    "    \n",
    "model_component_name = \"chronostraining\"\n",
    "tuning_step = create_model_component(model_component_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b53f1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_step(tuning_step):\n",
    "    model_name = tuning_step.display_name.split('-')[0]\n",
    "    best_model = PyTorchModel(\n",
    "        source_dir='model',\n",
    "        entry_point=model_name + \".py\",\n",
    "        role=role,\n",
    "        model_data=tuning_step.get_top_model_s3_uri(\n",
    "            top_k=0, \n",
    "            s3_bucket=bucket_name, \n",
    "            prefix=f\"{pipeline_name}/models\"\n",
    "        ),\n",
    "        image_uri=inference_image_uri,\n",
    "        sagemaker_session=pipeline_session,\n",
    "    )\n",
    "\n",
    "    model_step = ModelStep(\n",
    "        name=f'{model_name}-CreateModel',\n",
    "        display_name=f'{model_name}-CreateModel',\n",
    "        step_args=best_model.create(instance_type=instance_type),\n",
    "    )\n",
    "    return best_model, model_step, model_name\n",
    "\n",
    "best_model, model_step, model_name = create_model_step(tuning_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db854d93-e4f8-4a70-8d50-17b3ca57c642",
   "metadata": {},
   "source": [
    "<a id='model_registration'></a>\n",
    "### Model Registration\n",
    "\n",
    "After training and tuning our Chronos model, the final steps in our pipeline involve registering the best model and assembling all the steps into a cohesive pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b903eb70",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "registration_steps = {}\n",
    "\n",
    "register_args = best_model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[instance_type],\n",
    "    transform_instances=[instance_type],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    domain=\"MACHINE_LEARNING\",\n",
    "    description=\"Chronos\",\n",
    "    task=\"REGRESSION\",\n",
    "    framework=\"PYTORCH\",\n",
    "    image_uri=inference_image_uri\n",
    ")\n",
    "registration_steps = ModelStep(\n",
    "    name=model_name, \n",
    "    step_args=register_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5cce3d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "steps = [step_process, tuning_step, registration_steps]\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=pipeline_parameter_list,\n",
    "    steps=steps,\n",
    "    pipeline_experiment_config=PipelineExperimentConfig(\n",
    "        experiment_name,\n",
    "        Join(\n",
    "            on=\"-\", \n",
    "            values=[\n",
    "                \"ChronosForecastTrialExperiment\", \n",
    "                pipeline_name\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ec20e3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='pipeline_execution'></a>\n",
    "### Pipeline Execution\n",
    "\n",
    "After creating the pipeline, we will start the pipeline, wait for completion, list pipeline steps, and get a detailed description of the pipeline execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af326e84",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start()\n",
    "execution_id = execution.describe()['PipelineExecutionArn'].split('/')[-1]\n",
    "print(f\"Pipeline Execution ID: {execution_id}\")\n",
    "print(f\"Execution Artifacts Link: https://s3.console.aws.amazon.com/s3/buckets/sagemaker-{region}-{account_id}?prefix={pipeline_name}/executions/{execution_id}/&region={region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b5aae",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "try:\n",
    "    execution.wait()\n",
    "except Exception:\n",
    "    print(execution.list_steps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883955be",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ece76",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.1.0 Python 3.10 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-2.1.0-cpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
